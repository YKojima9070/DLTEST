from keras import backend as K
if 'tensorflow' == K.backend():
    import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
config.gpu_options.visible_device_list = "0"
set_session(tf.Session(config=config))
import keras.backend.tensorflow_backend 
from keras.backend.tensorflow_backend import set_session

import keras, os, glob
import numpy as np
np.set_printoptions(threshold=np.inf)
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.utils.np_utils import to_categorical
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from PIL import Image
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report


train_dir = 'C:\\Users\\Y.Kojima\\DLTEST\\cifar10\\IVI_cifar10' # 学習データ置き場
train_folder = os.listdir(train_dir)
test_dir = 'C:\\Users\\Y.Kojima\\DLTEST\\cifar10\\IVI_cifar10_test' # 評価データ置き場

image_size_x = 32 # 元画像サイズX
image_size_y = 32 # 元画像サイズY

X_train = [] # 学習に使う画像データの格納先
Y_train = [] # 学習に使うラベルデータの格納先
X_test = [] # 評価に使う画像データの格納先
Y_test = [] # 評価に使うラベルデータの格納先
Y_test_index = 1 # airplaneは１

# 学習ファイル用データ抜き出し
for index, name in enumerate(train_folder):
    dir = "./IVI_cifar10/" + name
    train_files = glob.glob(dir + "/*")
    for i, file in enumerate(train_files):
        image = Image.open(file)
        image = image.convert("RGB")
        image = image.resize((image_size_x, image_size_y))
        data = np.asarray(image)
        X_train.append(data) # 学習画像データをnumpy形式に変換
        Y_train.append(index) #　学習画像のラベルデータ(リストデータ)

# 評価ファイル用データ抜き出し
test_files = glob.glob(test_dir + "/*")
for i, file in enumerate(test_files):
    image = Image.open(file)
    image = image.convert("RGB")
    image = image.resize((image_size_x, image_size_y))
    data = np.asarray(image)
    X_test.append(data) # 評価画像データをnumpy形式に変換
    Y_test.append(Y_test_index) # 評価画像のラベルデータ(リストデータ)

# 学習データ、評価データをアレイデータに変換
X_train = np.array(X_train)
Y_train = np.array(Y_train)

X_test = np.array(X_test)
Y_test = np.array(Y_test)

#  学習画像データ、評価画像データの各ピクセルを255で割り0-1のデータで表示する
X_train = X_train.astype('float32') / 255
X_test = X_test.astype('float32') / 255

# 学習用ラベルデータ、評価用ラベルデータをリストからベクトル変換
Y_train = np_utils.to_categorical(Y_train, 10)
Y_test = np_utils.to_categorical(Y_test, 10)

# 以下学習パラメータ
num_classes = 10 # 分類項目数
batch_size = 32
epochs = 100
data_augmentation = True

# 以下学習レイヤー設定
model = Sequential() # Kerasのモデル指定
# CNN layer 1
model.add(Conv2D(32, (3, 3), padding='same',
                 input_shape=X_train.shape[1:]))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# CNN layer 2
model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# output
model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes))
model.add(Activation('softmax'))

# モデルのサマリーを表示
# print(model.summary())
model.compile(
loss='categorical_crossentropy', # 損失関数の設定
optimizer=Adam(lr=0.001), # 最適化法の指定
metrics=['accuracy'])

if not data_augmentation:
    print('Not using data augmentation.')
    model.fit(X_train, Y_train,
              batch_size=batch_size,
              epochs=epochs,
              validation_data=(X_test, Y_test),
              shuffle=True)
else:
    print('Using real-time data augmentation.')
    datagen = ImageDataGenerator(
        featurewise_center=False,
        samplewise_center=False,
        featurewise_std_normalization=False,
        samplewise_std_normalization=False,
        zca_whitening=False,
        zca_epsilon=1e-06,
        rotation_range=0,
        width_shift_range=0.1,
        height_shift_range=0.1,
        shear_range=0.,
        zoom_range=0.,
        channel_shift_range=0.,
        fill_mode='nearest',
        cval=0.,
        horizontal_flip=True,
        vertical_flip=False,
        rescale=None,
        preprocessing_function=None,
        data_format=None,
        validation_split=0)

    datagen.fit(X_train)
    model.fit_generator(datagen.flow(X_train, Y_train,
                                     batch_size=batch_size),
                        epochs=epochs,
                        validation_data=(X_test, Y_test),
                        workers=4)

score = model.evaluate(X_test, Y_test, verbose=0)
Y_pred = model.predict(X_test, verbose=1)

print('Test score:', score[0])
print('Test accuracy:', score[1])
print(confusion_matrix(np.argmax(Y_test, 1), np.argmax(Y_pred, 1)))
print(classification_report(np.argmax(Y_test, 1), np.argmax(Y_pred, 1)))

"""
folder = 'results'
if not os.path.exists(folder):
    os.makedirs(folder)

model.save(os.path.join(folder, 'my_model.h5'))
"""
